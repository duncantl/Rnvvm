<?xml version="1.0"?>
<article xmlns:r="http://www.r-project.org"
         xmlns:xi="http://www.w3.org/2003/XInclude">

  <!-- http://llvm.org/docs/NVPTXUsage.html  -->
<articleinfo>

<title></title>

<author><firstname>Duncan</firstname><surname>Temple Lang</surname>
  <affiliation><orgname>University of California at Davis</orgname>
               <orgdiv>Department of Statistics</orgdiv>
  </affiliation>
</author>
</articleinfo>

<section>
<title></title>

<!-- Need meta data on the kernel function -->

<para>
This is a short, simple and exploratory 
example of using libNVVM within <r/>.
The idea is  reasonably simple.
We write a function in <r/> and compile it using
<omg:pkg>Rllvm</omg:pkg> to <llvm/>'s IR language.
We then use libNVVM to convert the  IR code to PTX, in memory.
We then use the <omg:pkg>RCUDA</omg:pkg>  package to load
the PTX code into a usable form and then invoke the
kernel.
This illustrates writing a kernel function directly in <r/>
and then invoking it without using sub-process to compile the code,
but rather doing this in the <r/> session.

</para>

<para>
We start by writing a simple <r/> function which computes
the normal density for a single value.
<r:function>
Dnorm = function(x, mu = 0, sd = 1)
         1/sqrt(2 * pi * sd^2) * exp( - .5*( (x-mu)/sd ) ^2)
</r:function>
This is the same as <r:func>dnorm</r:func>, but not vectorized
and so a lot slower.  When we compile it with <llvm/>, it will be
close to as fast as the built-in version i <r/>.
However, one of the advantages is that we will be able to run the
computations in parallel on a GPU.
</para>

<para>
We now compile this code into <llvm/> IR using the
<omg:pkg>RLLVMCompile</omg:pkg>.  We'll use floats rather than doubles
for the GPU: <note><para>Fix the compiler to handle float.  Perhaps
problem is that in sd^2 the two values have different types - float
and numeric.  So we have to bend 2 to be a float in this case.
</para></note>
<r:code>
library(RLLVMCompile)
fc = compileFunction(Dnorm, FloatType, list(FloatType, FloatType, FloatType))
</r:code>
This creates a module and we can view the IR code with 
<r:func>showModule</r:func>.
We can also get the IR code as text with 
<r:code>
ir = showModule(fc, TRUE)
</r:code>
</para>

<para>
We can now convert the IR code to PTX using libNVVM.
<r:code>
library(Rnvvm)
ptx = generatePTX(ir, getName(fc))
</r:code>
This is a high-level function that uses the
following libNVVM steps:
<r:code eval="false">
prog = createProgram()
addModuleToProgram(prog, ir, "dnorm")
compileProgram(prog, character())
ptx = getCompiledResult(prog)
</r:code>
</para>

<para>
The <r:func>generatePTX</r:func> function returns the PTX code as a string.
We can now load this for use on the GPU with
<r:code>
library(RCUDA)
cuGetContext()
mod = cuModuleLoadDataEx(ptx)
</r:code>
</para>

<para>
We can now invoke the kernel.
We'll use 1 million observations:
<r:code>
N = 1e6L
x = rnorm(N)
.gpu(mod$Dnorm, x, 0, 1, output = numeric(N), gridDim = c(256, 128), blockDim = 32, output = "ans")
</r:code>
</para>




</section>
</article>
